{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imblanced Classification\n",
    "\n",
    "This notebook was created as part of a project to predict which members of a not for profit orginizaiton will renew their membership and which will cancel.  Getting useful results from an imbalanced data set like this one can be challenging.  Different methodologies can be applied to try and overcome this issue.    In addtion upsampling techniques are in the random Forest notebook and logistic regression notebook.  Smoteen is in the logistic regression notebook and one class SVM is in the SVM notebook.  Balanced weight  parameter for each type of model is in the notebooks for each respective model.  The results were not what we were hoping for but this is a very useful collection of many great techniques.  \n",
    "\n",
    "### try different classification thresholds\n",
    "We can change the threshold the model uses to decide whether the member is likely to cancel or renew.  The default threshold is 50%.  There are different ways to calculate what maybe a more appropriate threshold. This code is from  from https://machinelearningmastery.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "much of the code was adapted from https://machinelearningmastery.com/ \n",
    "some of the code including the upsampling and learning curves was adapted from the machine learning with python github repo\n",
    "various other resources also provided parts of the code.\n",
    "The code was edited to hide all proprietary information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import fbeta_score, make_scorer, f1_score, balanced_accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"format_variables_output4.csv\")\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# drop the entries for new members who joined leavig renewals and cancelations only\n",
    "data = data[data['Target']!=2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show the balance of the data set the renewal variable (1) has over 90% while cancelations are only 9.2%\n",
    "This imbalance in the data set will be a challenge of this predicitive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.907453\n",
       "0    0.092547\n",
       "Name: Target, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'MemberName', 'NF_Year', 'ACS_Year', 'JoinDate',\n",
       "       'ExpireDate', 'MemberStatus', 'State', 'StateName', 'StateCode',\n",
       "       'Region', 'SummaryLevel', 'CombinedFips', 'Target', 'TotalPopulation',\n",
       "       'MedianHouseholdIncome', 'MedianAge', 'NonHispanicWhites',\n",
       "       'TotalWorkers', 'UseCar', 'PopOver25', 'Bachelors', 'Agriculture',\n",
       "       'Construction', 'Manufacturing', 'WholesaleTrade', 'Retail',\n",
       "       'Transportation', 'Information', 'Finance', 'Professional', 'Education',\n",
       "       'Arts', 'OtherServices', 'PublicAdministration', 'ArmedForces',\n",
       "       'Years as Member', '1', '10', '12', '13', '15', '16', '17', '18', '19',\n",
       "       '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30',\n",
       "       '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40', '41',\n",
       "       '42', '44', '45', '46', '47', '48', '49', '5', '50', '51', '53', '54',\n",
       "       '55', '56', '6', '8', '9', 'Pop_Den', 'binned_pop_den',\n",
       "       'MedianIncomeAdjusted', '%NonHispanicWhites', '%DrivetoWork',\n",
       "       '%Bachelors', 'Industry', 'binned_pop_den_nums', 'Region_nums',\n",
       "       'municipality size', 'municipality size_nums'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data[['Target','TotalPopulation', 'MedianAge', 'MedianIncomeAdjusted', '%NonHispanicWhites',\n",
    "            '%DrivetoWork','%Bachelors','Pop_Den']]\n",
    "# data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing sets the classifier and its hyperparameters were selected in a different notebook\n",
    "X =  data1.drop(columns=['Target']).values\n",
    "y = data1['Target'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=101)\n",
    "clf = RandomForestClassifier(n_estimators = 100, random_state = 0, min_samples_leaf=2, min_samples_split =2, criterion =  'entropy', \n",
    "                             max_depth= None, max_features = 'log2', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try different classification thresholds\n",
    "We can change the threshold the model uses to decide whether the member is likely to cancel or renew.  The default threshold is 50%.  There are different ways to calculate what maybe a more appropriate threshold. This code is from  from https://machinelearningmastery.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.924667, G-Mean=0.593\n",
      "Best Threshold with Youden J=0.927714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "model = clf    \n",
    "model.fit(X_train, y_train)\n",
    "# predict probabilities\n",
    "yhat = model.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "yhat = yhat[:, 1]\n",
    "# calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(y_test, yhat)\n",
    "# calculate the g-mean for each threshold this takes into account the balance of specetivity and sensitivity \n",
    "gmeans = np.sqrt(tpr * (1-fpr))\n",
    "# locate the index of the largest g-mean\n",
    "ix = np.argmax(gmeans)\n",
    "print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
    "J = tpr - fpr\n",
    "ix = np.argmax(J)\n",
    "best_thresh = thresholds[ix]\n",
    "print('Best Threshold with Youden J=%f' % (best_thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.475333, F-Score=0.951\n"
     ]
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test, yhat)\n",
    "# convert to f score\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "# locate the index of the largest f score\n",
    "ix = np.argmax(fscore)\n",
    "print('Best Threshold=%f, F-Score=%.3f' % (thresholds[ix], fscore[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9509563511525257, 0.7052783571313973, 0.0]\n",
      "Threshold=0.475, F-Score=0.95096\n"
     ]
    }
   ],
   "source": [
    "# evaluate the 3 different thresholds to see which has the highest f1 score\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = yhat\n",
    "# define thresholds\n",
    "thresholds = [.475,.924667,927714]\n",
    "# evaluate each threshold\n",
    "scores = [f1_score(y_test, to_labels(probs, t)) for t in thresholds]\n",
    "# get best threshold\n",
    "ix = np.argmax(scores)\n",
    "print(scores)\n",
    "print('Threshold=%.3f, F-Score=%.5f' % (thresholds[ix], scores[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function which will apply threshold to positive probabilities to create labels of \n",
    "# of classified as 0 or 1 depending on if it is above or bleow the custom threshold\n",
    "def to_labels(pos_probs, threshold):\n",
    "    return (pos_probs >= threshold).astype('int') # true will return 1 false return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try different thresholds to see if we can create a better model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.02      0.04       406\n",
      "           1       0.91      1.00      0.95      3881\n",
      "\n",
      "    accuracy                           0.91      4287\n",
      "   macro avg       0.83      0.51      0.50      4287\n",
      "weighted avg       0.89      0.91      0.86      4287\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, to_labels(probs, .475))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.61      0.21       406\n",
      "           1       0.93      0.57      0.71      3881\n",
      "\n",
      "    accuracy                           0.57      4287\n",
      "   macro avg       0.53      0.59      0.46      4287\n",
      "weighted avg       0.86      0.57      0.66      4287\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, to_labels(probs, .924))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lower thresholds mean less negative labels which raises the precision on the cancelations and lowers the recall.  A higher threshold increases the recall as it is harder to get a positive label but of course the precision is lower.  The total f1 score for negatives is improved but the precision has droped too low. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.30      0.20       406\n",
      "           1       0.92      0.83      0.87      3881\n",
      "\n",
      "    accuracy                           0.78      4287\n",
      "   macro avg       0.54      0.56      0.54      4287\n",
      "weighted avg       0.85      0.78      0.81      4287\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, to_labels(probs, .85))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion:\n",
    "Changing the threshold didn't solve the problem and produce a useful model.  It may be something to come back to and combine with other methods and models if we can get a pretty good model this is a way to tweak the results,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample the data set to deal with class imbalance with upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    11786\n",
       "0     1202\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_imb =  data1.drop(columns=['Target']).values\n",
    "y_imb = data1['Target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_imb, y_imb , test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The split was done before the upsample. The upsampling was done only on the training data not the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of class 0 samples before: 802\n",
      "Number of class 0 samples after: 7899\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "print('Number of class 0 samples before:', X_train[y_train == 0].shape[0])\n",
    "\n",
    "X_upsampled, y_upsampled = resample(X_train[y_train == 0],\n",
    "                                    y_train[y_train == 0],\n",
    "                                    replace=True,\n",
    "                                    n_samples=X_train[y_train == 1].shape[0],\n",
    "                                    random_state=123)\n",
    "\n",
    "print('Number of class 0 samples after:', X_upsampled.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after increasing the number of cancelations (negative outcome) the training data is merged with the renewals (positive outcome). \n",
    "X_train = np.vstack((X_train[y_train == 1], X_upsampled))\n",
    "y_train = np.hstack((y_train[y_train == 1], y_upsampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  38  362]\n",
      " [  92 3795]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.10      0.14       400\n",
      "           1       0.91      0.98      0.94      3887\n",
      "\n",
      "    accuracy                           0.89      4287\n",
      "   macro avg       0.60      0.54      0.54      4287\n",
      "weighted avg       0.86      0.89      0.87      4287\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(X_train, y_train)\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "print(confusion_matrix(y_test,rfc_pred))\n",
    "print(classification_report(y_test,rfc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us more balance between recall and precision but not a great model.  In the Random Forest notebook this model is tweaked.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Down Sampling\n",
    "Lets try other techniques for imbalanced classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Target'\n",
    "X =  data1.drop(columns=['Target']).values\n",
    "y = data1['Target'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of class 1 samples before: 7905\n",
      "Number of class 0 samples after: 796\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "print('Number of class 1 samples before:', X_train[y_train == 1].shape[0])\n",
    "\n",
    "X_downsampled, y_downsampled = resample(X_train[y_train == 1],\n",
    "                                    y_train[y_train == 1],\n",
    "                                    replace=False,\n",
    "                                    n_samples=X_train[y_train == 0].shape[0],\n",
    "                                    random_state=123)\n",
    "\n",
    "print('Number of class 0 samples after:', X_downsampled.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.vstack((X_train[y_train == 0], X_downsampled))\n",
    "y_train = np.hstack((y_train[y_train == 0], y_downsampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 241  165]\n",
      " [1790 2091]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.59      0.20       406\n",
      "           1       0.93      0.54      0.68      3881\n",
      "\n",
      "    accuracy                           0.54      4287\n",
      "   macro avg       0.52      0.57      0.44      4287\n",
      "weighted avg       0.85      0.54      0.64      4287\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=50)\n",
    "rfc.fit(X_train, y_train)\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "print(confusion_matrix(y_test,rfc_pred))\n",
    "print(classification_report(y_test,rfc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion:\n",
    "We  didn't get great precision with the minority class and we have worse performance with the majority class.  The overall f1 is 54.  The dataset is too small to downsample.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smote (synthetic production of samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC AUC: 0.642\n"
     ]
    }
   ],
   "source": [
    "X =  data1.drop(columns=['Target']).values\n",
    "y = data1['Target'].values\n",
    "model = RandomForestClassifier()\n",
    "# evaluate without smote using the auc roc as criteria for scoring\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Mean ROC AUC: %.3f' % np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC AUC: 0.665\n"
     ]
    }
   ],
   "source": [
    "steps = [('over', SMOTE()), ('model', RandomForestClassifier())]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# evaluate with smote \n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Mean ROC AUC: %.3f' % np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "smote did help but not by much lets run it on a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit smote on the training data not the testing data\n",
    "sm = SMOTE(random_state = 2) \n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After OverSampling, the shape of train_X: (15770, 7)\n",
      "After OverSampling, the shape of train_y: (15770,) \n",
      "\n",
      "After OverSampling, counts of label '1': 7885\n",
      "After OverSampling, counts of label '0': 7885\n"
     ]
    }
   ],
   "source": [
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape)) \n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape)) \n",
    "  \n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res == 1))) \n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res == 0))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=50)\n",
    "rfc.fit(X_train_res, y_train_res)\n",
    "rfc_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 100  286]\n",
      " [ 460 3441]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.26      0.21       386\n",
      "           1       0.92      0.88      0.90      3901\n",
      "\n",
      "    accuracy                           0.83      4287\n",
      "   macro avg       0.55      0.57      0.56      4287\n",
      "weighted avg       0.86      0.83      0.84      4287\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,rfc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the results aren't improved enough to be helpful but the official research recomends combining smote with downsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of class 1 samples before: 7885\n",
      "Number of class 1 samples after: 6000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "print('Number of class 1 samples before:', X_train[y_train == 1].shape[0])\n",
    "\n",
    "X_downsampled, y_downsampled = resample(X_train[y_train == 1],\n",
    "                                    y_train[y_train == 1],\n",
    "                                    replace=False,\n",
    "                                    n_samples= 6000,\n",
    "                                    random_state=123)\n",
    "\n",
    "print('Number of class 1 samples after:', X_downsampled.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.vstack((X_train[y_train == 0], X_downsampled))\n",
    "y_train = np.hstack((y_train[y_train == 0], y_downsampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state = 2) \n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After OverSampling, the shape of train_X: (12000, 7)\n",
      "After OverSampling, the shape of train_y: (12000,) \n",
      "\n",
      "After OverSampling, counts of label '1': 6000\n",
      "After OverSampling, counts of label '0': 6000\n"
     ]
    }
   ],
   "source": [
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape)) \n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape)) \n",
    "  \n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res == 1))) \n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res == 0))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 101  285]\n",
      " [ 604 3297]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.26      0.19       386\n",
      "           1       0.92      0.85      0.88      3901\n",
      "\n",
      "    accuracy                           0.79      4287\n",
      "   macro avg       0.53      0.55      0.53      4287\n",
      "weighted avg       0.85      0.79      0.82      4287\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=50)\n",
    "rfc.fit(X_train_res, y_train_res)\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "print(confusion_matrix(y_test,rfc_pred))\n",
    "print(classification_report(y_test,rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  94  292]\n",
      " [ 556 3345]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.24      0.18       386\n",
      "           1       0.92      0.86      0.89      3901\n",
      "\n",
      "    accuracy                           0.80      4287\n",
      "   macro avg       0.53      0.55      0.53      4287\n",
      "weighted avg       0.85      0.80      0.82      4287\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=500)\n",
    "rfc.fit(X_train_res, y_train_res)\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "print(confusion_matrix(y_test,rfc_pred))\n",
    "print(classification_report(y_test,rfc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "\n",
    "Smote isn't a quick fix to the challenge.  If there was more time the data after smote and partial downsampling could be optimized with a grid search and evaluated with a learning curve.  The results were slightly better than with the upsampling.  There are still plenty of ways to try improving the model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   imblearn automatic balance\n",
    "\n",
    "This is a mehtod of imbalanced classification where weights are balanced to penalize wrong predictions of the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =  data1.drop(columns=['Target']).values\n",
    "y = data1['Target'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31839366 0.04858149 0.14584345 0.14208609 0.08401095 0.10735835\n",
      " 0.15372601]\n",
      "[[ 202  204]\n",
      " [1383 2498]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.50      0.20       406\n",
      "           1       0.92      0.64      0.76      3881\n",
      "\n",
      "    accuracy                           0.63      4287\n",
      "   macro avg       0.53      0.57      0.48      4287\n",
      "weighted avg       0.85      0.63      0.71      4287\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "\n",
    "                           \n",
    "clf = BalancedRandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train, y_train) \n",
    "\n",
    "print(clf.feature_importances_)  \n",
    "\n",
    "rfc_pred = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test,rfc_pred))\n",
    "print(classification_report(y_test,rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC AUC: 0.617\n"
     ]
    }
   ],
   "source": [
    "# class balanced random forest for imbalanced classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# define model\n",
    "model = RandomForestClassifier(n_estimators=100, class_weight='balanced')\n",
    "# define evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "# summarize performance\n",
    "print('Mean ROC AUC: %.3f' % np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  21  385]\n",
      " [   9 3872]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.05      0.10       406\n",
      "           1       0.91      1.00      0.95      3881\n",
      "\n",
      "    accuracy                           0.91      4287\n",
      "   macro avg       0.80      0.52      0.52      4287\n",
      "weighted avg       0.89      0.91      0.87      4287\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train) \n",
    "\n",
    "\n",
    "rfc_pred = model.predict(X_test)\n",
    "print(confusion_matrix(y_test,rfc_pred))\n",
    "print(classification_report(y_test,rfc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "The Roc score of .617 was lower than what was achieved above with smote and the default random Forest model.  However the precison was much better than with the unweighted models run earlier.  The recall is still pretty low with upsampling we were able to get it to 15%.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation forest  and one class classification\n",
    "to deal with the weight imbalance of our dataset we can try anamoly detection to train a model on only the majority class and let the model attempt to detect any entries which are very different from the majority class.  This is another techniques used for imbalanced classification.  Several are tried here and one class SVM is in notebook 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"format_variables_output4.csv\")\n",
    "data = data[data['Target']!=2]\n",
    "data1 = data[['Target','TotalPopulation', 'MedianAge', 'MedianIncomeAdjusted', '%NonHispanicWhites',\n",
    "            '%DrivetoWork','%Bachelors','Pop_Den']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data1[data1['Target'] == 1]\n",
    "X_outliers = data1[data1['Target'] == 0]\n",
    "X_train =  X_train .drop(columns=['Target']).values\n",
    "X_outliers = X_outliers.drop(columns=['Target']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.18970000e+04, 3.73000000e+01, 8.62020000e+04, ...,\n",
       "        8.23887118e-01, 2.24009615e-01, 1.16000000e+01],\n",
       "       [5.22900000e+03, 3.98000000e+01, 5.75100000e+04, ...,\n",
       "        7.51542575e-01, 1.89542484e-01, 3.61800000e+02],\n",
       "       [7.64000000e+02, 4.16000000e+01, 5.77040000e+04, ...,\n",
       "        4.50363196e-01, 1.39534884e-01, 1.26500000e+02],\n",
       "       ...,\n",
       "       [3.21330000e+04, 4.25000000e+01, 5.46940000e+04, ...,\n",
       "        9.29135338e-01, 1.71725677e-01, 5.70880000e+03],\n",
       "       [1.04290000e+04, 4.04000000e+01, 7.79340000e+04, ...,\n",
       "        9.34215168e-01, 1.79156745e-01, 2.01500000e+02],\n",
       "       [3.17400000e+03, 4.37000000e+01, 5.69320000e+04, ...,\n",
       "        8.65715983e-01, 1.33936262e-01, 6.93000000e+01]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brody\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_iforest.py:248: FutureWarning: 'behaviour' is deprecated in 0.22 and will be removed in 0.24. You should not pass or set this parameter.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "\n",
    "# contamination paramater is set to the proportion of outliers \n",
    "clf = IsolationForest(contamination=0.091, behaviour='new')\n",
    "clf.fit(X_train)\n",
    "\n",
    "# predictions\n",
    "y_pred_train = clf.predict(X_train)\n",
    "y_pred_test = clf.predict(X_test)\n",
    "y_pred_outliers = clf.predict(X_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9099603452297644\n"
     ]
    }
   ],
   "source": [
    "# new, 'normal' observations ----\n",
    "print(\"Accuracy:\", list(y_pred_test).count(1)/y_pred_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.09068219633943428\n"
     ]
    }
   ],
   "source": [
    "# outliers ----\n",
    "print(\"Accuracy:\", list(y_pred_outliers).count(-1)/y_pred_outliers.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brody\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_iforest.py:248: FutureWarning: 'behaviour' is deprecated in 0.22 and will be removed in 0.24. You should not pass or set this parameter.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.099\n"
     ]
    }
   ],
   "source": [
    "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.33, random_state=2, stratify=y)\n",
    "# define outlier detection model\n",
    "model = IsolationForest(contamination=0.091, behaviour='new')\n",
    "# fit on majority class\n",
    "trainX = trainX[trainy==1]\n",
    "model.fit(trainX)\n",
    "# detect outliers in the test set\n",
    "yhat = model.predict(testX)\n",
    "# mark inliers 1, outliers -1\n",
    "testy[testy == 1] = 1\n",
    "testy[testy == 0] = -1\n",
    "# calculate score\n",
    "score = f1_score(testy, yhat, pos_label=-1)\n",
    "print('F1 Score: %.3f' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "isolation forest did not predict many outliers we can detect 9% by guessing randomly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Outlier Factor to predict outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"format_variables_output4.csv\")\n",
    "data = data[data['Target']!=2]\n",
    "data1 = data[['Target','TotalPopulation', 'MedianAge', 'MedianIncomeAdjusted', '%NonHispanicWhites',\n",
    "            '%DrivetoWork','%Bachelors','Pop_Den']]\n",
    "X =  data1.drop(columns=['Target']).values\n",
    "y = data1['Target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.095\n"
     ]
    }
   ],
   "source": [
    "from numpy import vstack\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    " \n",
    "# make a prediction with a lof model\n",
    "def lof_predict(model, trainX, testX):\n",
    "\t# create one large dataset\n",
    "\tcomposite = vstack((trainX, testX))\n",
    "\t# make prediction on composite dataset\n",
    "\tyhat = model.fit_predict(composite)\n",
    "\t# return just the predictions on the test set\n",
    "\treturn yhat[len(trainX):]\n",
    " \n",
    "# split into train/test sets\n",
    "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.33, random_state=2, stratify=y)\n",
    "# define outlier detection model \n",
    "model = LocalOutlierFactor(contamination=0.091)  # contamination is the proportion of outliers\n",
    "# get examples for just the majority class\n",
    "trainX = trainX[trainy==0]\n",
    "# detect outliers in the test set\n",
    "yhat = lof_predict(model, trainX, testX)\n",
    "# mark inliers 1, outliers -1\n",
    "testy[testy == 1] = 1\n",
    "testy[testy == 0] = -1\n",
    "# calculate score\n",
    "score = f1_score(testy, yhat, pos_label=-1)\n",
    "print('F1 Score: %.3f' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The f1 score was even lower than with isolation forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost\n",
    "\n",
    "Sometimes different algorithms will help for an imbalanced data set.  Lets try boosting with adaboost which is simular to the Random Forest model.  This code and results are in the Random Forest notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### easy ensemble \n",
    "which creates different data sets by selecting random samples of the majority class and balancing with the minority class and using adaboost.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =  data1.drop(columns=['Target']).values\n",
    "y = data1['Target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC AUC: 0.591\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "\n",
    "\n",
    "# define model\n",
    "model = EasyEnsembleClassifier(n_estimators=10)\n",
    "# define evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "# summarize performance\n",
    "print('Mean ROC AUC: %.3f' % np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 218  188]\n",
      " [1698 2183]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.54      0.19       406\n",
      "           1       0.92      0.56      0.70      3881\n",
      "\n",
      "    accuracy                           0.56      4287\n",
      "   macro avg       0.52      0.55      0.44      4287\n",
      "weighted avg       0.84      0.56      0.65      4287\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=101)\n",
    "model.fit(X_train, y_train) \n",
    "\n",
    "rfc_pred = model.predict(X_test)\n",
    "print(confusion_matrix(y_test,rfc_pred))\n",
    "print(classification_report(y_test,rfc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model did not perform as well as others tested above.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
